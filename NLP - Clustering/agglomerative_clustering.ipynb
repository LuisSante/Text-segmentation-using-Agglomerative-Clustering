{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from matplotlib import pyplot as plt\n",
    "from autocorrect import Speller #autocorrector\n",
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import itertools\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bertopic in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: sentence-transformers>=0.4.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bertopic) (2.2.0)\n",
      "Requirement already satisfied: pyyaml<6.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bertopic) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bertopic) (1.22.4)\n",
      "Requirement already satisfied: pandas>=1.1.5 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bertopic) (1.4.2)\n",
      "Requirement already satisfied: hdbscan>=0.8.28 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bertopic) (0.8.28)\n",
      "Requirement already satisfied: plotly>=4.7.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bertopic) (5.10.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bertopic) (1.1.1)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bertopic) (4.64.0)\n",
      "Requirement already satisfied: umap-learn>=0.5.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bertopic) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hdbscan>=0.8.28->bertopic) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hdbscan>=0.8.28->bertopic) (1.8.0)\n",
      "Requirement already satisfied: cython>=0.27 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hdbscan>=0.8.28->bertopic) (0.29.28)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.1.5->bertopic) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from plotly>=4.7.0->bertopic) (8.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (4.19.2)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (1.11.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (0.12.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (3.7)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (0.1.96)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (0.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.41.1->bertopic) (0.4.4)\n",
      "Requirement already satisfied: numba>=0.49 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from umap-learn>=0.5.0->bertopic) (0.55.2)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from umap-learn>=0.5.0->bertopic) (0.5.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (65.0.2)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.38.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->bertopic) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (4.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2.26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2022.4.24)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (21.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (3.7.0)\n",
      "Requirement already satisfied: click in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.0.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (9.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (3.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bertopic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura del dataset \"app_reviews\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package_name</th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com.mantz_it.rfanalyzer</td>\n",
       "      <td>Great app! The new version now works on my Bra...</td>\n",
       "      <td>October 12 2016</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>com.mantz_it.rfanalyzer</td>\n",
       "      <td>Great It's not fully optimised and has some is...</td>\n",
       "      <td>August 23 2016</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>com.mantz_it.rfanalyzer</td>\n",
       "      <td>Works on a Nexus 6p I'm still messing around w...</td>\n",
       "      <td>August 04 2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>com.mantz_it.rfanalyzer</td>\n",
       "      <td>The bandwidth seemed to be limited to maximum ...</td>\n",
       "      <td>July 25 2016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>com.mantz_it.rfanalyzer</td>\n",
       "      <td>Works well with my Hackrf Hopefully new update...</td>\n",
       "      <td>July 22 2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288060</th>\n",
       "      <td>com.termux.api</td>\n",
       "      <td>it doesn't do anything after installing this i...</td>\n",
       "      <td>June 24 2016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288061</th>\n",
       "      <td>com.termux.api</td>\n",
       "      <td>I like this app . Its is very helpful for use....</td>\n",
       "      <td>June 20 2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288062</th>\n",
       "      <td>com.termux.api</td>\n",
       "      <td>Finally Brings back the Unix command line to A...</td>\n",
       "      <td>May 20 2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288063</th>\n",
       "      <td>com.termux.api</td>\n",
       "      <td>The API feature is great  just need loads more...</td>\n",
       "      <td>May 05 2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288064</th>\n",
       "      <td>com.termux.api</td>\n",
       "      <td>Works Nicely! I wish there were instructions t...</td>\n",
       "      <td>April 28 2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288065 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   package_name  \\\n",
       "0       com.mantz_it.rfanalyzer   \n",
       "1       com.mantz_it.rfanalyzer   \n",
       "2       com.mantz_it.rfanalyzer   \n",
       "3       com.mantz_it.rfanalyzer   \n",
       "4       com.mantz_it.rfanalyzer   \n",
       "...                         ...   \n",
       "288060           com.termux.api   \n",
       "288061           com.termux.api   \n",
       "288062           com.termux.api   \n",
       "288063           com.termux.api   \n",
       "288064           com.termux.api   \n",
       "\n",
       "                                                   review             date  \\\n",
       "0       Great app! The new version now works on my Bra...  October 12 2016   \n",
       "1       Great It's not fully optimised and has some is...   August 23 2016   \n",
       "2       Works on a Nexus 6p I'm still messing around w...   August 04 2016   \n",
       "3       The bandwidth seemed to be limited to maximum ...     July 25 2016   \n",
       "4       Works well with my Hackrf Hopefully new update...     July 22 2016   \n",
       "...                                                   ...              ...   \n",
       "288060  it doesn't do anything after installing this i...     June 24 2016   \n",
       "288061  I like this app . Its is very helpful for use....     June 20 2016   \n",
       "288062  Finally Brings back the Unix command line to A...      May 20 2016   \n",
       "288063  The API feature is great  just need loads more...      May 05 2016   \n",
       "288064  Works Nicely! I wish there were instructions t...    April 28 2016   \n",
       "\n",
       "        star  \n",
       "0          4  \n",
       "1          4  \n",
       "2          5  \n",
       "3          3  \n",
       "4          5  \n",
       "...      ...  \n",
       "288060     3  \n",
       "288061     5  \n",
       "288062     5  \n",
       "288063     5  \n",
       "288064     5  \n",
       "\n",
       "[288065 rows x 4 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#review = pd.read_csv('https://raw.githubusercontent.com/LuisSante/Datasets/main/app_reviews.csv')\n",
    "review = pd.read_csv('C:/Users/USUARIO/Documents/Universidad/4A. Inteligencia Artificial/Dataset/app_reviews.csv')\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza del dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_corpus(corpus_review):\n",
    "        \n",
    "    for i in range(len(corpus_review)):        \n",
    "        corpus_review[i] = re.sub(r'https?:\\/\\/.\\S+', \"\", corpus_review[i]) \n",
    "        corpus_review[i] = re.sub(r'\"', '', corpus_review[i]) \n",
    "        corpus_review[i] = re.sub(r'#', '', corpus_review[i]) \n",
    "        corpus_review[i] = re.sub(r'^RT[\\s]+', '', corpus_review[i]) \n",
    "              \n",
    "        Apos_dict={\"'s\":\" is\",\"n't\":\" not\",\"'m\":\" am\",\"'    ll\":\" will\", \n",
    "               \"'d\":\" would\",\"'ve\":\" have\",\"'re\":\" are\"} #reemplazar apostrofes    \n",
    "          \n",
    "        for key,value in Apos_dict.items(): \n",
    "            if key in corpus_review[i]: \n",
    "                corpus_review[i]=corpus_review[i].replace(key,value) #reemplazar\n",
    "\n",
    "        corpus_review[i] = \" \".join([s for s in re.split(\"([A-Z][a-z]+[^A-Z]*)\",corpus_review[i]) if s])\n",
    "        corpus_review[i]=corpus_review[i].lower() #minusculas\n",
    "\n",
    "        file=open(\"slang.txt\",\"r\") #jergas del ingles\n",
    "        slang=file.read() \n",
    "          \n",
    "        slang=slang.split('\\n') \n",
    "          \n",
    "        tweet_tokens= corpus_review[i].split() \n",
    "        slang_word=[] \n",
    "        meaning=[] \n",
    "          \n",
    "        for line in slang: \n",
    "            temp=line.split(\"=\") \n",
    "            slang_word.append(temp[0]) \n",
    "            meaning.append(temp[-1]) \n",
    "          \n",
    "        for i,word in enumerate(tweet_tokens): \n",
    "            if word in slang_word: \n",
    "                idx=slang_word.index(word) \n",
    "                tweet_tokens[i]=meaning[idx] \n",
    "                  \n",
    "        corpus_review[i]=\" \".join(tweet_tokens) \n",
    "        corpus_review[i] = ''.join(''.join(s)[:2] for _, s in itertools.groupby(corpus_review[i]))   \n",
    " \n",
    "        spell = Speller(lang='en') \n",
    "        corpus_review[i]=spell(corpus_review[i]) \n",
    "    return corpus_review\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se extrae en un corpus todos los reviews o criticas de usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_corpus(dataset):\n",
    "    lista = []  \n",
    "    for i in range(len(dataset['package_name'].unique())):#iterar entre los package_name unicos\n",
    "        dataset_temp = dataset.loc[dataset['package_name'] == dataset['package_name'].unique()[i]]\n",
    "        lista.append({'package_name':dataset['package_name'].unique()[i], 'size': len(dataset_temp)})#otener un package_name y el número de oraciones\n",
    "\n",
    "    lista = sorted(lista, key=lambda x: x['size'], reverse=True)#se ordena para saber que package_name tiene el mayor n° de oraciones\n",
    "    dataframe = dataset[dataset['package_name'] == lista[8]['package_name']]#el mayor será el elemnto que ocupa la posicion 0\n",
    "    corpus = list(dataframe['review'])#extraemos un corpus\n",
    "    \n",
    "    #corpus = clean_corpus(corpus)\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertir datos en un Dataframe a un manejo más ágil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_corpus_to_dataFrame(corpus):\n",
    "    corpus_ds = {\n",
    "        'Sentences' : corpus\n",
    "    }\n",
    "\n",
    "    dataset_new = pd.DataFrame(corpus_ds)\n",
    "    return dataset_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_embbedings_to_dataFrame(embeddings):\n",
    "    array = []\n",
    "    for i in embeddings:\n",
    "        array.append([i])\n",
    "\n",
    "    dataset_new = pd.DataFrame(array, columns=['Embeddings'])\n",
    "    return dataset_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se crea una función que nos permita incrustar las oraciones, para esto usamos un modelo pre-entrenado de SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_embeddings(dataset):\n",
    "    model_embedder = SentenceTransformer('all-MiniLM-L6-v2')#modelo pre-entrenado\n",
    "    corpus = extract_corpus(dataset)#extraemos un corpus del dataset \n",
    "\n",
    "    embeddings = model_embedder.encode(corpus, \n",
    "                                        convert_to_tensor=False, \n",
    "                                        show_progress_bar=True) #generamos las incrustaciones \n",
    "\n",
    "    embeddings = embeddings /  np.linalg.norm(embeddings, axis=1, keepdims=True) #normalizamos\n",
    "\n",
    "    return embeddings, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_embeddings_queries(queries):\n",
    "    model_embedder = SentenceTransformer('all-MiniLM-L6-v2')#modelo pre-entrenado\n",
    "\n",
    "    embeddings_queries = model_embedder.encode(queries, \n",
    "                                        convert_to_tensor=False, \n",
    "                                        show_progress_bar=True) #generamos las incrustaciones \n",
    "\n",
    "    embeddings_queries = embeddings_queries /  np.linalg.norm(embeddings_queries, axis=0, keepdims=True) #normalizamos\n",
    "\n",
    "    return embeddings_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para obtener el \"mejor\" cluster aplicamos el método de la silueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#en esta funcion hace la tarea de obtener el mejor k con agglomerative clustering\n",
    "def silhoutte(dataset, attempts):\n",
    "\n",
    "    embeddings, corpus = neural_embeddings(dataset)\n",
    "    scores_silhouette = [] #guardaremos todos los resultados del método de la silueta para devolver el mayor\n",
    "\n",
    "    for k in range(2,attempts+1):\n",
    "\n",
    "        agglomerative_clusterering = AgglomerativeClustering(n_clusters=k, \n",
    "                                                            affinity=\"cosine\" , \n",
    "                                                            linkage=\"complete\").fit(embeddings)\n",
    "                                                            \n",
    "        cluster_labels = agglomerative_clusterering.labels_\n",
    "\n",
    "        silhouette_avg = silhouette_score(embeddings, cluster_labels)\n",
    "        scores_silhouette.append(silhouette_avg)\n",
    "\n",
    "    max_score = max(scores_silhouette)\n",
    "    max_index = scores_silhouette.index(max_score)\n",
    "    n_clusters = max_index + 2\n",
    "\n",
    "    return n_clusters, embeddings, corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Al tener el \"mejor\" número de clusters, se procede a segmentar las oraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topics_segmentation(dataset_review, attempts):\n",
    "    n_clusters, embeddings, corpus = silhoutte(dataset_review, attempts) # se le pasa el mejor K\n",
    "\n",
    "    agglomerative_clusterering = AgglomerativeClustering(n_clusters=n_clusters, \n",
    "                                                        affinity=\"cosine\", \n",
    "                                                        linkage=\"complete\").fit(embeddings)\n",
    "                                                        \n",
    "    cluster_labels = agglomerative_clusterering.labels_ #obtengo las etiquetas respectivas a las oraciones\n",
    "\n",
    "    model_topics = BERTopic(nr_topics = n_clusters).fit(corpus) # entreno para sacar K temas \n",
    "    label_topics = model_topics.generate_topic_labels() # temas\n",
    "    label_topics.pop(0) #elimino el grupo de temas atípicos\n",
    "\n",
    "    print(label_topics)\n",
    "\n",
    "    return cluster_labels, label_topics, embeddings, corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A cada oración le asignamos el cluster al que pertenece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(dataset_review, attempts):\n",
    "    cluster_labels, label_topics, embeddings, corpus = topics_segmentation(dataset_review, attempts)\n",
    "\n",
    "    corpus_dataframe = convert_corpus_to_dataFrame(corpus) #de set de oraciones se convierte en un DF para asignarle su número de cluster\n",
    "    corpus_dataframe['cluster'] = cluster_labels #se le asigna a cada oración un cluster\n",
    "    \n",
    "    '''topics = [] # creo una lista para llenar con los temas segun el cluster respectivo\n",
    "    for i in corpus_dataframe['cluster']: \n",
    "        topics.append(label_topics[i])\n",
    "\n",
    "    corpus_dataframe['Topics'] = topics #creo una columna TOPICS que indica el tema de cada cluster'''\n",
    "\n",
    "    return embeddings, label_topics, corpus_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Búsqueda semántica para encontrar el tema de cada cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(dataset_review, attemps):\n",
    "    embeddings, label_topics, corpus_dataframe = clustering(dataset_review, attemps)\n",
    "    dataframe_embeddings = convert_embbedings_to_dataFrame(embeddings)\n",
    "\n",
    "    dataframe_embeddings['cluster'] = corpus_dataframe['cluster']\n",
    "    sort_embeddings =  dataframe_embeddings.sort_values(by=['cluster'])\n",
    "    sort_embeddings = sort_embeddings.reset_index(drop=True)\n",
    "    nr_clusters = sort_embeddings['cluster'].unique()\n",
    "    \n",
    "    print(len(nr_clusters))\n",
    "    print(len(sort_embeddings))\n",
    "    print(sort_embeddings)\n",
    "    print(nr_clusters)\n",
    "\n",
    "    first_sentences = []\n",
    "    j = 0\n",
    "    for i in range(len(sort_embeddings)):               \n",
    "        if(j < len(nr_clusters) and sort_embeddings['cluster'][i] == nr_clusters[j]):\n",
    "            print(\"j: \",j)\n",
    "            first_sentences.append(sort_embeddings['Embeddings'][i])\n",
    "            j+=1\n",
    "\n",
    "    print(first_sentences)\n",
    "    print(len(first_sentences))\n",
    "\n",
    "    queries = label_topics\n",
    "    topics = []\n",
    "    for query in queries:\n",
    "        embeddings_queries = neural_embeddings_queries(query)\n",
    "        cos_scores = util.cos_sim(embeddings_queries, first_sentences)[0]\n",
    "\n",
    "        cos_scores_numpy = cos_scores.numpy()\n",
    "        cos_scores_list = cos_scores_numpy.tolist()\n",
    "        max_coincidence = max(cos_scores_list)\n",
    "        index = cos_scores_list.index(max_coincidence)\n",
    "        topics.append({query , index})\n",
    "\n",
    "    print(topics)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbbaf465860490f83ef348a84efe077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0_app_great_good', '1_weather_the_not']\n",
      "2\n",
      "2099\n",
      "                                             Embeddings  cluster\n",
      "0     [-0.11320456, 0.027211675, 0.023340745, -0.053...        0\n",
      "1     [-0.123598136, 0.062280484, 0.05117411, -0.081...        0\n",
      "2     [-0.041777987, 0.10871419, 0.022554228, -0.080...        0\n",
      "3     [-0.05273707, 0.0024701075, -0.0006009123, 0.0...        0\n",
      "4     [-0.020272695, -0.036391795, 0.03406607, -0.03...        0\n",
      "...                                                 ...      ...\n",
      "2094  [-0.040672235, -0.009908965, 0.025821224, -0.0...        1\n",
      "2095  [0.005858691, 0.024118843, 0.008889248, 0.0503...        1\n",
      "2096  [-0.044284828, -0.024861367, -0.01832826, 0.04...        1\n",
      "2097  [-0.053155173, 0.063662276, 0.031657554, -0.03...        1\n",
      "2098  [-0.11557477, 0.09539389, -0.01849673, -0.0799...        1\n",
      "\n",
      "[2099 rows x 2 columns]\n",
      "[0 1]\n",
      "j:  0\n",
      "j:  1\n",
      "[array([-1.13204561e-01,  2.72116754e-02,  2.33407449e-02, -5.30632660e-02,\n",
      "        5.66631323e-03,  2.30870359e-02,  3.20470445e-02, -4.42133211e-02,\n",
      "        1.70556717e-02, -3.42545770e-02, -8.44197795e-02,  4.85146046e-02,\n",
      "       -3.59501913e-02, -5.79485260e-02,  8.07667226e-02, -6.21950254e-02,\n",
      "        7.79624134e-02,  4.01233519e-05,  4.27483544e-02, -1.39953941e-02,\n",
      "       -5.55458181e-02, -7.38725960e-02,  4.09838334e-02,  9.99616757e-02,\n",
      "        3.59497704e-02,  2.17093714e-02, -2.42150831e-03,  3.42141353e-02,\n",
      "        6.24871487e-03,  9.64365155e-03, -5.40797450e-02,  8.03563558e-03,\n",
      "        5.44985570e-03,  5.15306666e-02, -7.36084282e-02, -6.46656798e-03,\n",
      "        8.67121741e-02,  2.73792893e-02, -6.71080947e-02, -3.64945317e-03,\n",
      "        6.82391077e-02,  1.92529503e-02, -1.13636302e-03,  3.20722349e-02,\n",
      "        2.61141006e-02,  2.38550268e-03, -2.04604622e-02, -9.13274139e-02,\n",
      "       -3.17513570e-02,  5.62858544e-02,  2.70030405e-02, -1.08403534e-01,\n",
      "       -1.91384200e-02, -6.10781126e-02,  2.69045793e-02,  9.99462008e-02,\n",
      "        1.16885481e-02,  2.73080934e-02,  5.15681840e-02,  7.63185173e-02,\n",
      "        2.51411702e-02,  1.91047310e-03,  1.32919289e-02, -1.41077377e-02,\n",
      "        4.61976118e-02, -1.71392858e-02,  6.33438081e-02,  2.19248384e-02,\n",
      "        4.26832726e-03, -4.22220342e-02,  7.65004456e-02,  1.09283403e-02,\n",
      "        1.61511346e-03, -9.48627107e-03, -7.18345344e-02,  5.87247219e-03,\n",
      "        1.88803896e-02, -8.86254665e-03,  4.18217815e-02,  4.80884314e-02,\n",
      "       -4.34113964e-02,  2.14609560e-02,  3.82311493e-02,  6.37017563e-02,\n",
      "        5.03895022e-02, -7.46359304e-02, -7.10243033e-03,  8.71604010e-02,\n",
      "       -3.90832461e-02, -2.83286311e-02, -2.10032463e-02,  5.54191619e-02,\n",
      "       -2.32053660e-02, -1.02866553e-02, -2.33608540e-02,  4.36494313e-02,\n",
      "        1.49378795e-02, -6.27989322e-02, -7.83700198e-02,  2.91838087e-02,\n",
      "        1.04979798e-03, -9.00651887e-03,  3.88695188e-02,  7.44118020e-02,\n",
      "        2.53974739e-02,  2.84164101e-02, -5.43487035e-02, -2.77849473e-02,\n",
      "       -6.91631883e-02,  1.52689693e-02, -2.23144125e-02,  1.75803974e-02,\n",
      "       -2.67892294e-02, -3.76676954e-02, -6.06097095e-02,  6.49526492e-02,\n",
      "       -9.82657596e-02,  4.04546224e-02,  9.33420435e-02,  3.48527208e-02,\n",
      "        9.68524814e-02, -2.06715264e-03, -4.24484313e-02, -7.56108239e-02,\n",
      "       -3.60250729e-03,  9.83948261e-02, -1.30910315e-02, -2.25166264e-34,\n",
      "       -2.56411638e-03,  1.13464743e-01,  3.45145240e-02, -1.90922935e-02,\n",
      "        5.15549816e-02,  4.89725322e-02, -1.19736150e-01,  4.16410062e-03,\n",
      "       -1.75224319e-02, -2.50646658e-02,  2.19649486e-02,  2.30524968e-02,\n",
      "       -6.38544858e-02, -2.65384354e-02,  2.16384865e-02, -9.66879129e-02,\n",
      "       -2.61231768e-03,  1.98240243e-02,  8.92926846e-03, -8.63595232e-02,\n",
      "       -8.25420115e-03, -3.49951573e-02, -1.00320779e-01, -1.22632748e-02,\n",
      "       -3.23255477e-03,  4.81014177e-02,  4.56179157e-02, -1.25272414e-02,\n",
      "       -2.39612851e-02,  2.70806439e-02,  1.95683390e-02, -4.17047068e-02,\n",
      "        3.77342291e-02, -1.04913609e-02,  7.37238536e-03, -1.19888224e-01,\n",
      "       -8.71415138e-02, -7.43439794e-02,  3.75203192e-02,  2.35547889e-02,\n",
      "        3.50874360e-03, -8.57433155e-02, -1.44123035e-02, -6.31405413e-02,\n",
      "        8.82409047e-03,  9.25826952e-02,  6.95785061e-02, -6.27381802e-02,\n",
      "        6.46771863e-02,  7.95487780e-03,  2.28287987e-02,  9.11154505e-03,\n",
      "       -4.46279980e-02, -6.01773001e-02, -4.42660274e-03, -7.16987578e-03,\n",
      "        5.13775125e-02,  2.42105275e-02,  1.39299054e-02, -9.26365703e-03,\n",
      "       -2.70455834e-02, -3.12924273e-02,  6.69761747e-02,  1.07866023e-02,\n",
      "       -2.23935600e-02,  8.30850676e-02, -6.38742447e-02,  2.16977112e-02,\n",
      "       -8.10718571e-04,  7.12779835e-02,  2.75614485e-02,  9.37764812e-03,\n",
      "        6.66330978e-02,  5.52131161e-02,  8.06790031e-03,  1.82473455e-02,\n",
      "        5.68362214e-02,  1.02581491e-03, -1.33841455e-01, -4.98763472e-02,\n",
      "        8.63511954e-03, -7.93564469e-02,  3.24927233e-02,  2.38369983e-02,\n",
      "        2.10773423e-02, -4.79454659e-02,  7.75580779e-02, -2.47622319e-02,\n",
      "        1.65068712e-02, -3.43182422e-02, -2.16498431e-02, -8.20712820e-02,\n",
      "        8.07611495e-02, -2.88851094e-03, -1.19933367e-01,  3.11173237e-34,\n",
      "        2.60550268e-02, -5.95295243e-02, -5.00964280e-03, -3.15651298e-02,\n",
      "        5.02070710e-02, -2.74936929e-02,  5.13897452e-04,  1.67305376e-02,\n",
      "       -3.06697655e-02,  1.01893581e-01,  6.73584044e-02,  7.07591102e-02,\n",
      "       -8.44676327e-03, -2.73582786e-02, -3.91668864e-02,  4.70001474e-02,\n",
      "        8.82809758e-02, -2.59434376e-02, -5.47173200e-04, -1.15477383e-01,\n",
      "        5.07270321e-02, -7.44945705e-02, -4.41958569e-02, -2.67598461e-02,\n",
      "        4.95781116e-02, -3.65800261e-02,  4.24820967e-02,  9.21229459e-03,\n",
      "        3.27682570e-02, -3.45780747e-03, -4.66277525e-02, -7.75814988e-03,\n",
      "        6.10766187e-02,  3.20818089e-02,  8.64248723e-02, -1.67177245e-02,\n",
      "        3.04848850e-02, -7.71007985e-02, -1.16485633e-01, -1.08733270e-02,\n",
      "        4.10305150e-03,  8.81565269e-03,  2.73695663e-02, -1.03945727e-03,\n",
      "       -2.47868560e-02,  1.51934177e-01,  3.30711529e-02,  2.35047787e-02,\n",
      "       -2.75623817e-02,  6.01952896e-02,  7.25591779e-02, -5.12761697e-02,\n",
      "        1.85501128e-02, -2.92188041e-02, -5.73421903e-02,  2.09393632e-02,\n",
      "        4.85722721e-02,  6.70312811e-03, -1.54063320e-02,  3.03647015e-02,\n",
      "        7.28878565e-03, -3.43588516e-02, -1.79456305e-02, -8.46608281e-02,\n",
      "        6.75231079e-03, -1.91868581e-02,  2.54644565e-02,  1.12891696e-01,\n",
      "        2.63558216e-02,  1.95370950e-02,  4.94194254e-02, -1.03294123e-02,\n",
      "       -9.56430659e-03,  2.71200365e-03, -1.04726190e-02,  1.07523091e-01,\n",
      "        7.31486753e-02,  1.61265116e-02, -1.02605551e-01, -3.53542380e-02,\n",
      "        1.60334948e-02,  1.22193005e-02,  4.13920917e-02, -2.50078198e-02,\n",
      "       -3.84356938e-02,  2.04879008e-02, -5.48661640e-03,  7.81106576e-02,\n",
      "       -4.17001359e-02,  1.66634083e-04, -1.24668039e-01,  7.51072913e-02,\n",
      "       -2.11926475e-02,  1.01017565e-01,  1.36755891e-02, -2.97661789e-08,\n",
      "        2.32797079e-02,  2.82128546e-02,  1.66647937e-02, -7.14856312e-02,\n",
      "        5.59649663e-03, -7.85423443e-02,  7.79413944e-03, -4.84005623e-02,\n",
      "       -7.97241740e-03,  6.68517035e-03, -6.18464388e-02, -1.21536635e-01,\n",
      "       -4.21404280e-02, -1.74604766e-02,  2.60311514e-02,  4.83417232e-03,\n",
      "       -6.27891570e-02,  5.26876822e-02, -2.81447750e-02, -8.13379735e-02,\n",
      "        2.72024702e-02,  9.24645662e-02,  6.18299209e-02, -4.18595262e-02,\n",
      "       -8.93273205e-02,  5.63376434e-02, -7.19051361e-02,  7.31494054e-02,\n",
      "        5.41111827e-02,  3.30365859e-02,  1.35738663e-02,  1.01806829e-02,\n",
      "        7.99773335e-02, -2.25903075e-02, -7.51011148e-02, -5.79140447e-02,\n",
      "       -8.51713493e-02,  4.67018895e-02,  8.98890495e-02,  3.97083908e-02,\n",
      "        5.03592454e-02, -1.11295931e-01, -6.42845109e-02,  1.62651949e-02,\n",
      "       -5.62514514e-02, -4.25021956e-03,  2.10703705e-02, -1.19020827e-01,\n",
      "       -3.92946117e-02,  4.50956076e-02,  3.56418081e-02,  5.83103672e-03,\n",
      "       -3.86816598e-02,  5.20181730e-02,  9.78606637e-04,  5.30106239e-02,\n",
      "       -2.31491439e-02, -1.83879044e-02, -1.16422428e-02, -4.69452888e-02,\n",
      "       -4.05657291e-02,  1.67230088e-02,  2.23383494e-02,  6.97199106e-02],\n",
      "      dtype=float32), array([-9.04401690e-02, -1.58579927e-02,  4.69753295e-02,  2.99169552e-02,\n",
      "        3.75387296e-02, -5.34064956e-02,  7.78504685e-02,  3.41608785e-02,\n",
      "       -1.57632846e-02, -2.03505103e-02, -2.00809725e-02, -3.64786834e-02,\n",
      "        7.18243839e-03,  8.52029398e-03, -1.31035700e-01,  1.23329684e-02,\n",
      "       -1.29598649e-02,  6.34306818e-02, -1.28817901e-01, -4.51541469e-02,\n",
      "       -7.01386034e-02,  2.97577791e-02, -3.13419029e-02, -7.49468803e-02,\n",
      "        1.78226326e-02,  3.37011926e-02,  2.70819142e-02,  4.82693240e-02,\n",
      "       -3.13391127e-02, -2.41076611e-02,  7.06768036e-02,  5.18632941e-02,\n",
      "        7.43632168e-02, -1.73226893e-02, -2.85283718e-02, -3.15616541e-02,\n",
      "       -5.81004582e-02,  4.74546803e-03,  7.20090792e-02,  4.62806178e-03,\n",
      "       -2.99330037e-02, -6.07743263e-02,  5.57843223e-02, -3.67092602e-02,\n",
      "        7.11257830e-02,  6.14232607e-02, -1.48499841e-02, -7.34081417e-02,\n",
      "       -3.24979983e-02,  5.60406782e-03,  8.61100927e-02, -1.65467821e-02,\n",
      "       -4.55301069e-02, -7.65479822e-03, -2.03205328e-02,  8.66122395e-02,\n",
      "       -8.48723501e-02,  5.18629588e-02,  4.26062681e-02, -5.44902775e-03,\n",
      "       -3.68509367e-02,  4.99977879e-02, -3.82253388e-03,  2.45109033e-02,\n",
      "        2.31647100e-02, -5.86968195e-03, -3.52348462e-02, -5.44709899e-02,\n",
      "       -5.00389077e-02,  7.57779256e-02,  1.91656733e-03,  7.78502002e-02,\n",
      "       -7.58142248e-02,  3.10014673e-02,  1.41323674e-02,  5.79137355e-02,\n",
      "        3.03211920e-02, -5.72175980e-02, -8.17945602e-06,  1.98022346e-03,\n",
      "        4.44960371e-02, -4.46290337e-02, -4.24722023e-02,  2.21389513e-02,\n",
      "       -2.12766118e-02,  3.80842364e-03,  2.98308320e-02, -6.10375172e-03,\n",
      "        2.15061959e-02,  2.58052279e-03, -3.13611589e-02, -4.71379571e-02,\n",
      "       -1.02254888e-02,  1.69542879e-02, -3.72183435e-02,  5.57993464e-02,\n",
      "       -2.66960878e-02, -9.59112402e-03, -1.11173205e-01,  1.46289632e-01,\n",
      "        1.41117712e-02, -3.90208587e-02,  9.21907574e-02,  1.39329555e-02,\n",
      "       -3.46792564e-02, -3.13664898e-02,  1.61414910e-02,  5.50965108e-02,\n",
      "       -5.03644273e-02, -3.45571227e-02,  9.15397517e-03,  7.69666284e-02,\n",
      "        2.43657604e-02, -1.25659746e-03,  2.63102297e-02, -2.56445119e-03,\n",
      "       -7.75545165e-02,  3.35775353e-02,  8.40860903e-02, -2.73783784e-02,\n",
      "        2.75275800e-02,  2.37684045e-02,  3.99454124e-02,  2.33943667e-02,\n",
      "       -9.42525640e-02, -1.33291662e-01, -2.23203637e-02,  4.51287549e-35,\n",
      "        7.24544143e-03, -2.80999672e-02,  1.07052096e-03, -1.41272845e-03,\n",
      "        5.34586571e-02,  5.85687310e-02,  2.81878896e-02,  1.73776336e-02,\n",
      "       -1.36521205e-01, -7.90819824e-02, -3.10674403e-03, -2.05097795e-02,\n",
      "        4.63887770e-03,  2.96367146e-03,  1.45087531e-02, -1.79035962e-02,\n",
      "        6.78857118e-02, -2.63661649e-02,  3.68316122e-03,  1.44781021e-03,\n",
      "       -4.01555793e-03,  2.98207183e-03,  4.37736623e-02, -2.60781627e-02,\n",
      "       -2.18234342e-02, -3.74353980e-03,  1.03942920e-02, -1.41069159e-01,\n",
      "        6.47250041e-02,  7.40221888e-02, -6.75546099e-03, -1.31902741e-02,\n",
      "        4.62323464e-02,  4.01034802e-02, -2.45874953e-02,  3.87410820e-02,\n",
      "        2.78567411e-02, -1.22498283e-02,  3.34804170e-02, -7.00642988e-02,\n",
      "       -1.89268496e-02,  5.81135191e-02, -8.01497921e-02,  7.89506212e-02,\n",
      "       -1.87885389e-02,  1.60112724e-01,  6.68210164e-02, -3.53977829e-02,\n",
      "        2.42482703e-02, -1.68973505e-02,  5.37401177e-02, -2.35973820e-02,\n",
      "       -5.83965592e-02, -4.15386586e-03, -1.69373415e-02, -1.78787410e-02,\n",
      "       -5.99624030e-03,  3.53082865e-02, -2.90154805e-03, -4.57748510e-02,\n",
      "        1.00821964e-01,  4.33202088e-02, -7.91303720e-03,  5.05264150e-03,\n",
      "       -1.59536302e-02, -3.82549614e-02,  1.21775959e-02, -5.04093915e-02,\n",
      "       -1.65356733e-02,  1.18211107e-02, -4.95159589e-02, -4.47535031e-02,\n",
      "        9.77561697e-02, -3.72766890e-02,  2.25676801e-02, -2.75674891e-02,\n",
      "        3.22603621e-02,  1.82722863e-02,  5.22612361e-03, -2.40889993e-02,\n",
      "       -4.07560617e-02, -1.85366813e-02,  2.65532713e-02,  4.39746119e-02,\n",
      "        1.98001089e-03, -7.34801367e-02, -7.72962943e-02, -2.45225355e-02,\n",
      "       -2.21643411e-02,  1.65491691e-03, -8.03994834e-02, -4.53567058e-02,\n",
      "        1.33913029e-02, -4.93107736e-02, -8.28650221e-02,  5.92783388e-34,\n",
      "        1.46300243e-02,  5.00140041e-02,  1.77016843e-03,  1.42487735e-01,\n",
      "        3.95311713e-02,  2.21415106e-02,  4.91123870e-02, -5.06750867e-02,\n",
      "        3.84679474e-02,  3.63925882e-02,  1.37341497e-02, -1.28069699e-01,\n",
      "       -2.63360259e-03, -5.60122877e-02,  1.44832715e-01,  6.14998564e-02,\n",
      "        1.22033902e-01,  5.83695024e-02, -4.00766283e-02,  7.56237358e-02,\n",
      "       -2.43186373e-02, -1.38503844e-02,  5.03341407e-02, -3.33019532e-02,\n",
      "        1.73637867e-02,  1.02395052e-03,  4.60816436e-02,  4.43361178e-02,\n",
      "       -5.56688271e-02,  1.98374987e-02, -7.47404702e-04, -2.85501387e-02,\n",
      "       -4.10646014e-02, -6.09665737e-02, -1.41064599e-02,  7.97882676e-02,\n",
      "        9.94814783e-02, -1.53372819e-02, -1.13946358e-02, -8.53803474e-03,\n",
      "        9.51889902e-03, -2.11610161e-02, -1.29143000e-01, -2.86112595e-02,\n",
      "        1.20756533e-02, -9.19862688e-02,  5.43912500e-02,  3.04461997e-02,\n",
      "        8.14091265e-02,  3.76878902e-02, -1.08361919e-03, -7.34446719e-02,\n",
      "       -1.39619987e-02,  9.08217579e-02, -5.90814166e-02, -7.10068643e-03,\n",
      "        2.12515015e-02,  1.84424594e-02, -2.41932683e-02,  2.41461527e-02,\n",
      "        1.48526477e-02,  7.72571340e-02,  5.72244462e-04,  3.13277096e-02,\n",
      "        3.60794179e-02,  1.01175107e-01, -1.23071074e-02, -8.09966102e-02,\n",
      "        6.51773182e-04, -5.21410406e-02,  7.07493201e-02, -5.15372865e-02,\n",
      "       -1.71360373e-01,  2.76219044e-02,  4.56151068e-02, -3.22407931e-02,\n",
      "       -1.79052260e-02, -4.74317484e-02, -6.15622997e-02,  1.47871654e-02,\n",
      "        2.83290967e-02, -8.38925466e-02,  3.89878713e-02, -6.34047610e-04,\n",
      "        4.95092459e-02, -6.84866235e-02,  2.38686781e-02,  7.83716291e-02,\n",
      "       -5.13801984e-02, -4.12703119e-02, -1.50433099e-02,  5.54835983e-02,\n",
      "        8.99637416e-02, -7.26940036e-02,  5.98844737e-02, -1.69420122e-08,\n",
      "       -8.00169259e-03,  5.35518080e-02, -6.16973592e-03, -3.88529859e-02,\n",
      "        4.61141653e-02,  3.62687111e-02,  7.92953894e-02, -6.01264238e-02,\n",
      "        3.20575349e-02,  7.23175779e-02,  8.61260593e-02,  2.77408008e-02,\n",
      "        6.68021664e-02,  5.28588928e-02,  5.52405268e-02, -1.49680786e-02,\n",
      "       -2.54783276e-02,  8.36009458e-02,  1.05280807e-04, -1.92084052e-02,\n",
      "       -8.92284699e-03,  3.75224929e-03, -2.26739477e-02, -2.16234811e-02,\n",
      "       -3.70272473e-02, -2.16223914e-02, -9.18899029e-02,  6.59768283e-02,\n",
      "        8.20520222e-02,  8.10203608e-03,  1.85809024e-02,  1.14289923e-02,\n",
      "       -1.31491628e-02, -1.23965479e-02, -6.16820715e-02, -3.77852917e-02,\n",
      "       -8.94171372e-02, -1.52287250e-02,  6.96092786e-04,  3.70266028e-02,\n",
      "        4.21189796e-03,  3.15497890e-02,  5.34409732e-02, -6.46506026e-02,\n",
      "       -1.03174269e-01,  8.17191042e-03,  3.55670182e-03, -1.00519806e-02,\n",
      "        1.71613880e-02, -3.92777380e-03,  2.07218360e-02,  5.85112767e-03,\n",
      "        5.54191880e-03,  1.20689362e-01,  7.53113106e-02, -3.84356193e-02,\n",
      "        4.56092954e-02,  1.13712922e-02, -5.34643233e-02, -2.03906875e-02,\n",
      "        6.84087351e-02,  1.99382827e-02,  3.92436376e-03,  5.07411640e-03],\n",
      "      dtype=float32)]\n",
      "2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29558219b839452fa77d540dd75efe8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c58073d9494419da47dfe84fb06dfce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'0_app_great_good', 1}, {'1_weather_the_not', 1}]\n"
     ]
    }
   ],
   "source": [
    "semantic_search(review, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0, 'A man is eating pasta.'},\n",
       " {7, 'Someone in a gorilla costume is playing a set of drums.'},\n",
       " {8, 'A cheetah chases prey on across a field.'}]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "corpus = ['A man is eating food.',\n",
    "          'A man is eating a piece of bread.',\n",
    "          'The girl is carrying a baby.',\n",
    "          'A man is riding a horse.',\n",
    "          'A woman is playing violin.',\n",
    "          'Two men pushed carts through the woods.',\n",
    "          'A man is riding a white horse on an enclosed ground.',\n",
    "          'A monkey is playing drums.',\n",
    "          'A cheetah is running behind its prey.'\n",
    "          ]\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=False)\n",
    "\n",
    "queries = ['A man is eating pasta.', 'Someone in a gorilla costume is playing a set of drums.', 'A cheetah chases prey on across a field.']\n",
    "\n",
    "topics = []\n",
    "for query in queries:\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=False)\n",
    "\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    cos_scores_numpy = cos_scores.numpy()\n",
    "    cos_scores_list = cos_scores_numpy.tolist()\n",
    "    max_coincidence = max(cos_scores_list)\n",
    "    index = cos_scores_list.index(max_coincidence)\n",
    "    topics.append({query , index})\n",
    "\n",
    "topics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para dar visualización de estas oraciones en un plano euclidiano, aplicamos una técnica de reducción de dimensiones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimension_reduction(embeddings):\n",
    "    scaler = umap.UMAP(n_components=2).fit_transform(embeddings)\n",
    "    dimension_2d = pd.DataFrame(scaler, columns=['x', 'y'])\n",
    "    return dimension_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostraremos un gráfico de la segmentación de oraciones y un DataFrame de las oraciones con su respectivo cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_graphics_and_themes(dataset_review, attemps):\n",
    "    embeddings, corpus_dataframe = clustering(dataset_review, attemps)\n",
    "    review_2d = dimension_reduction(embeddings) #se reduce a dos dimensiones las incrustaciones para poder plotear\n",
    "\n",
    "    review_2d['labels'] = corpus_dataframe['cluster']\n",
    "    review_2d['Topics'] = corpus_dataframe['Topics'] \n",
    "    \n",
    "    plt.figure(figsize=(20, 20))\n",
    "    clustered = review_2d[review_2d.labels != -1]\n",
    "    #print(\"clustered\", clustered)\n",
    "    plt.scatter(review_2d.x, \n",
    "                review_2d.y, \n",
    "                c=clustered.labels, \n",
    "                s=20,\n",
    "                cmap='Spectral')\n",
    "    #plt.legend(review_2d['Topics'])\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    return corpus_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topics = show_graphics_and_themes(review, 40)\n",
    "#topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USUARIO\\Documents\\Proyectos-4toA\\Text-segmentation-using-Agglomerative-Clustering\\NLP - Clustering\\agglomerative_clustering.ipynb Celda 29\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/USUARIO/Documents/Proyectos-4toA/Text-segmentation-using-Agglomerative-Clustering/NLP%20-%20Clustering/agglomerative_clustering.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m topics[\u001b[39m'\u001b[39m\u001b[39mTopics\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'topics' is not defined"
     ]
    }
   ],
   "source": [
    "#topics['Topics'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def show_dimentions(distribution):\\n    for col in \\'xy\\':\\n        sns.kdeplot(distribution[col], shade=True)\\n\\n    with sns.axes_style(style=\\'ticks\\'):\\n       g = sns.factorplot(data=distribution, kind=\"box\")'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def show_dimentions(distribution):\n",
    "    for col in 'xy':\n",
    "        sns.kdeplot(distribution[col], shade=True)\n",
    "\n",
    "    with sns.axes_style(style='ticks'):\n",
    "       g = sns.factorplot(data=distribution, kind=\"box\")'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "110fe3fb9777db4ce1f884af3cc527a40b2c98427ad17781c021ef692bd3d28d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
