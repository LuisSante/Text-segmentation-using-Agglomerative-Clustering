{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marit\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "#from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "#from sklearn.preprocessing import normalize, LabelEncoder, StandardScaler, MinMaxScaler\n",
    "#from sklearn.manifold import TSNE, LocallyLinearEmbedding, SpectralEmbedding\n",
    "from sklearn.decomposition import KernelPCA, SparsePCA, TruncatedSVD, PCA\n",
    "from matplotlib import pyplot as plt\n",
    "#import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package_name</th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com.mantz_it.rfanalyzer</td>\n",
       "      <td>Great app! The new version now works on my Bra...</td>\n",
       "      <td>October 12 2016</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>com.mantz_it.rfanalyzer</td>\n",
       "      <td>Great It's not fully optimised and has some is...</td>\n",
       "      <td>August 23 2016</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>com.mantz_it.rfanalyzer</td>\n",
       "      <td>Works on a Nexus 6p I'm still messing around w...</td>\n",
       "      <td>August 04 2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>com.mantz_it.rfanalyzer</td>\n",
       "      <td>The bandwidth seemed to be limited to maximum ...</td>\n",
       "      <td>July 25 2016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>com.mantz_it.rfanalyzer</td>\n",
       "      <td>Works well with my Hackrf Hopefully new update...</td>\n",
       "      <td>July 22 2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288060</th>\n",
       "      <td>com.termux.api</td>\n",
       "      <td>it doesn't do anything after installing this i...</td>\n",
       "      <td>June 24 2016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288061</th>\n",
       "      <td>com.termux.api</td>\n",
       "      <td>I like this app . Its is very helpful for use....</td>\n",
       "      <td>June 20 2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288062</th>\n",
       "      <td>com.termux.api</td>\n",
       "      <td>Finally Brings back the Unix command line to A...</td>\n",
       "      <td>May 20 2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288063</th>\n",
       "      <td>com.termux.api</td>\n",
       "      <td>The API feature is great  just need loads more...</td>\n",
       "      <td>May 05 2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288064</th>\n",
       "      <td>com.termux.api</td>\n",
       "      <td>Works Nicely! I wish there were instructions t...</td>\n",
       "      <td>April 28 2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288065 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   package_name  \\\n",
       "0       com.mantz_it.rfanalyzer   \n",
       "1       com.mantz_it.rfanalyzer   \n",
       "2       com.mantz_it.rfanalyzer   \n",
       "3       com.mantz_it.rfanalyzer   \n",
       "4       com.mantz_it.rfanalyzer   \n",
       "...                         ...   \n",
       "288060           com.termux.api   \n",
       "288061           com.termux.api   \n",
       "288062           com.termux.api   \n",
       "288063           com.termux.api   \n",
       "288064           com.termux.api   \n",
       "\n",
       "                                                   review             date  \\\n",
       "0       Great app! The new version now works on my Bra...  October 12 2016   \n",
       "1       Great It's not fully optimised and has some is...   August 23 2016   \n",
       "2       Works on a Nexus 6p I'm still messing around w...   August 04 2016   \n",
       "3       The bandwidth seemed to be limited to maximum ...     July 25 2016   \n",
       "4       Works well with my Hackrf Hopefully new update...     July 22 2016   \n",
       "...                                                   ...              ...   \n",
       "288060  it doesn't do anything after installing this i...     June 24 2016   \n",
       "288061  I like this app . Its is very helpful for use....     June 20 2016   \n",
       "288062  Finally Brings back the Unix command line to A...      May 20 2016   \n",
       "288063  The API feature is great  just need loads more...      May 05 2016   \n",
       "288064  Works Nicely! I wish there were instructions t...    April 28 2016   \n",
       "\n",
       "        star  \n",
       "0          4  \n",
       "1          4  \n",
       "2          5  \n",
       "3          3  \n",
       "4          5  \n",
       "...      ...  \n",
       "288060     3  \n",
       "288061     5  \n",
       "288062     5  \n",
       "288063     5  \n",
       "288064     5  \n",
       "\n",
       "[288065 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = pd.read_csv('https://raw.githubusercontent.com/LuisSante/Datasets/main/app_reviews.csv')\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se extrae en un corpus todos los reviews o criticas de usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_corpus(dataset):\n",
    "    lista = []  \n",
    "    for i in range(len(dataset['package_name'].unique())):\n",
    "        dataset_temp = dataset.loc[dataset['package_name'] == dataset['package_name'].unique()[i]]\n",
    "        lista.append({'package_name':dataset['package_name'].unique()[i], 'size': len(dataset_temp)})\n",
    "\n",
    "    lista = sorted(lista, key=lambda x: x['size'], reverse=True)\n",
    "    dataframe = dataset[dataset['package_name'] == lista[8]['package_name']]\n",
    "    corpus = list(dataframe['review'])\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_corpus_to_dataFrame(corpus):\n",
    "    corpus_ds = {\n",
    "        'Sentences' : corpus\n",
    "    }\n",
    "\n",
    "    dataset_new = pd.DataFrame(corpus_ds)\n",
    "    return dataset_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea una funcion que nos permita hacer una incrustacion de palabras con un dataset dado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_embeddings(dataset):\n",
    "    model_embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    corpus = extract_corpus(dataset)\n",
    "\n",
    "    corpus_embeddings = model_embedder.encode(corpus, convert_to_tensor=True, show_progress_bar=True)\n",
    "    corpus_embeddings = corpus_embeddings /  np.linalg.norm(corpus_embeddings, axis=1, keepdims=True)\n",
    "\n",
    "    return corpus_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos tambien la funcion para el metodo de la silueta, este recibe dos argumentos: el dataset y el numero de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhoutte(dataset, attempts):\n",
    "\n",
    "    embeddings = neural_embeddings(dataset)\n",
    "    scores_silhouette = []\n",
    "\n",
    "    for k in range(2,attempts):\n",
    "\n",
    "        agglomerative_clusterering = AgglomerativeClustering(n_clusters=k, affinity=\"cosine\" , linkage=\"complete\").fit(embeddings)\n",
    "        cluster_labels = agglomerative_clusterering.labels_\n",
    "\n",
    "        silhouette_avg = silhouette_score(embeddings, cluster_labels)\n",
    "        scores_silhouette.append(silhouette_avg)\n",
    "\n",
    "    max_score = max(scores_silhouette)\n",
    "    max_index = scores_silhouette.index(max_score)\n",
    "    n_clusters = max_index + 2\n",
    "\n",
    "    return n_clusters, embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace una funcion para la segmentación del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(dataset_review, attempts):\n",
    "    n_clusters, embeddings = silhoutte(dataset_review, attempts)\n",
    "\n",
    "    agglomerative_clusterering = AgglomerativeClustering(n_clusters=n_clusters, affinity=\"cosine\" , linkage=\"complete\").fit(embeddings)\n",
    "    cluster_labels = agglomerative_clusterering.labels_\n",
    "\n",
    "    return n_clusters, cluster_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta funcion se dedica a realizar el clustering del dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clustering(dataset_review, attempts):\n",
    "    n_clusters, labels = segmentation(dataset_review, attempts)\n",
    "    corpus_dataset = extract_corpus(dataset_review)\n",
    "\n",
    "    clustered_sentences = {}\n",
    "    for sentence_id, cluster_id in enumerate(labels):\n",
    "        if cluster_id not in clustered_sentences:\n",
    "            clustered_sentences[cluster_id] = []\n",
    "    \n",
    "        clustered_sentences[cluster_id].append(corpus_dataset[sentence_id])\n",
    "    \n",
    "    for i, cluster in clustered_sentences.items():\n",
    "        print(\"Cluster \", i+1)\n",
    "        print(cluster)\n",
    "        print(\"     \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ultimo se muestra el dataset final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marit\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_utils.py:133: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:68.)\n",
      "  t = torch.tensor([], dtype=storage.dtype, device=storage._untyped().device)\n",
      "Batches: 100%|██████████| 93/93 [00:37<00:00,  2.48it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\marit\\Documents\\UNSA\\ICC\\Text-segmentation-using-Agglomerative-Clustering\\NLP - Clustering\\agglomerative_clustering.ipynb Celda 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/marit/Documents/UNSA/ICC/Text-segmentation-using-Agglomerative-Clustering/NLP%20-%20Clustering/agglomerative_clustering.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m clustering(review, \u001b[39m10\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\marit\\Documents\\UNSA\\ICC\\Text-segmentation-using-Agglomerative-Clustering\\NLP - Clustering\\agglomerative_clustering.ipynb Celda 16\u001b[0m in \u001b[0;36mclustering\u001b[1;34m(dataset_review, attempts)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marit/Documents/UNSA/ICC/Text-segmentation-using-Agglomerative-Clustering/NLP%20-%20Clustering/agglomerative_clustering.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclustering\u001b[39m(dataset_review, attempts):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/marit/Documents/UNSA/ICC/Text-segmentation-using-Agglomerative-Clustering/NLP%20-%20Clustering/agglomerative_clustering.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     n_clusters, labels \u001b[39m=\u001b[39m segmentation(dataset_review, attempts)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marit/Documents/UNSA/ICC/Text-segmentation-using-Agglomerative-Clustering/NLP%20-%20Clustering/agglomerative_clustering.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     corpus_dataset \u001b[39m=\u001b[39m extract_corpus(dataset_review)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marit/Documents/UNSA/ICC/Text-segmentation-using-Agglomerative-Clustering/NLP%20-%20Clustering/agglomerative_clustering.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     clustered_sentences \u001b[39m=\u001b[39m {}\n",
      "\u001b[1;32mc:\\Users\\marit\\Documents\\UNSA\\ICC\\Text-segmentation-using-Agglomerative-Clustering\\NLP - Clustering\\agglomerative_clustering.ipynb Celda 16\u001b[0m in \u001b[0;36msegmentation\u001b[1;34m(dataset_review, attempts)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marit/Documents/UNSA/ICC/Text-segmentation-using-Agglomerative-Clustering/NLP%20-%20Clustering/agglomerative_clustering.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msegmentation\u001b[39m(dataset_review, attempts):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/marit/Documents/UNSA/ICC/Text-segmentation-using-Agglomerative-Clustering/NLP%20-%20Clustering/agglomerative_clustering.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     n_clusters, embeddings \u001b[39m=\u001b[39m silhoutte(dataset_review, attempts)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marit/Documents/UNSA/ICC/Text-segmentation-using-Agglomerative-Clustering/NLP%20-%20Clustering/agglomerative_clustering.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     agglomerative_clusterering \u001b[39m=\u001b[39m AgglomerativeClustering(n_clusters\u001b[39m=\u001b[39mn_clusters, affinity\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcosine\u001b[39m\u001b[39m\"\u001b[39m , linkage\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcomplete\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mfit(embeddings)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marit/Documents/UNSA/ICC/Text-segmentation-using-Agglomerative-Clustering/NLP%20-%20Clustering/agglomerative_clustering.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     cluster_labels \u001b[39m=\u001b[39m agglomerative_clusterering\u001b[39m.\u001b[39mlabels_\n",
      "\u001b[1;32mc:\\Users\\marit\\Documents\\UNSA\\ICC\\Text-segmentation-using-Agglomerative-Clustering\\NLP - Clustering\\agglomerative_clustering.ipynb Celda 16\u001b[0m in \u001b[0;36msilhoutte\u001b[1;34m(dataset, attempts)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marit/Documents/UNSA/ICC/Text-segmentation-using-Agglomerative-Clustering/NLP%20-%20Clustering/agglomerative_clustering.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msilhoutte\u001b[39m(dataset, attempts):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/marit/Documents/UNSA/ICC/Text-segmentation-using-Agglomerative-Clustering/NLP%20-%20Clustering/agglomerative_clustering.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     embeddings \u001b[39m=\u001b[39m neural_embeddings(dataset)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marit/Documents/UNSA/ICC/Text-segmentation-using-Agglomerative-Clustering/NLP%20-%20Clustering/agglomerative_clustering.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     scores_silhouette \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marit/Documents/UNSA/ICC/Text-segmentation-using-Agglomerative-Clustering/NLP%20-%20Clustering/agglomerative_clustering.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m,attempts):\n",
      "\u001b[1;32mc:\\Users\\marit\\Documents\\UNSA\\ICC\\Text-segmentation-using-Agglomerative-Clustering\\NLP - Clustering\\agglomerative_clustering.ipynb Celda 16\u001b[0m in \u001b[0;36mneural_embeddings\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marit/Documents/UNSA/ICC/Text-segmentation-using-Agglomerative-Clustering/NLP%20-%20Clustering/agglomerative_clustering.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m corpus \u001b[39m=\u001b[39m extract_corpus(dataset)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marit/Documents/UNSA/ICC/Text-segmentation-using-Agglomerative-Clustering/NLP%20-%20Clustering/agglomerative_clustering.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m corpus_embeddings \u001b[39m=\u001b[39m model_embedder\u001b[39m.\u001b[39mencode(corpus, convert_to_tensor\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, show_progress_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/marit/Documents/UNSA/ICC/Text-segmentation-using-Agglomerative-Clustering/NLP%20-%20Clustering/agglomerative_clustering.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m corpus_embeddings \u001b[39m=\u001b[39m corpus_embeddings \u001b[39m/\u001b[39m  np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(corpus_embeddings, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, keepdims\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marit/Documents/UNSA/ICC/Text-segmentation-using-Agglomerative-Clustering/NLP%20-%20Clustering/agglomerative_clustering.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mreturn\u001b[39;00m corpus_embeddings\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\linalg\\linalg.py:2500\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2349\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_norm_dispatcher)\n\u001b[0;32m   2350\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnorm\u001b[39m(x, \u001b[39mord\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   2351\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2352\u001b[0m \u001b[39m    Matrix or vector norm.\u001b[39;00m\n\u001b[0;32m   2353\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2498\u001b[0m \n\u001b[0;32m   2499\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2500\u001b[0m     x \u001b[39m=\u001b[39m asarray(x)\n\u001b[0;32m   2502\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39missubclass\u001b[39m(x\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, (inexact, object_)):\n\u001b[0;32m   2503\u001b[0m         x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_tensor.py:757\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    755\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    756\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 757\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    758\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    759\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "clustering(review, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_dim(corpus_embeddings):\n",
    "    scaler = PCA(n_components=2, random_state = 100)\n",
    "    X_principal = scaler.fit_transform(corpus_embeddings)\n",
    "    X_principal.shape\n",
    "    X_principal\n",
    "    distribution = pd.DataFrame(X_principal, columns=['x', 'y'])\n",
    "    distribution\n",
    "    \n",
    "    return X_principal, distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dimentions(distribution):\n",
    "    for col in 'xy':\n",
    "        sns.kdeplot(distribution[col], shade=True)\n",
    "\n",
    "    with sns.axes_style(style='ticks'):\n",
    "       g = sns.factorplot(data=distribution, kind=\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2281628.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [12]\u001b[1;36m\u001b[0m\n\u001b[1;33m    def show_graphics(corpus_embeddings,X_principal,clustering_model.labels_):\u001b[0m\n\u001b[1;37m                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def show_graphics(corpus_embeddings,X_principal,clustering_model):\n",
    "    point_size = 100.0 / np.sqrt(corpus_embeddings.shape[0])\n",
    "    result = pd.DataFrame(X_principal, columns=['x', 'y'])\n",
    "    result['labels'] = clustering_model.labels_\n",
    "    print(result)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    clustered = result[result.labels != -1]\n",
    "    plt.scatter(clustered.x, clustered.y, c=clustered.labels, s=20, cmap='Spectral')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
